{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After running the Scrapy scraper, the data needs to be processed. This wrangler is structured to handle the scraper's output file for the Examination type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PSLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list()\n",
    "\n",
    "with open('./scraper/export/psle.jl', 'r') as File:\n",
    "    for line in File:\n",
    "        l.append((json.loads(line)))\n",
    "    File.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each json line, extract key/value into a tuple. This is based on the Item pipeline structure from Scrapy\n",
    "list_of_dfs_with_metadata = [(j['tables'][0], j['region'], j['district'], j['school']) for j in l]\n",
    "\n",
    "#Make a list of just the DFs\n",
    "list_of_dfs = [df[0] for df in list_of_dfs_with_metadata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attach the metadata to the actual DataFrame as new columns. Though rare, we do expect some errors might occur\n",
    "#as a result of a pipeline failure. Currently, one example is a whole school's scores being invalidated (*W marker).\n",
    "#In this instance, nothing went wrong with the scraping, but the process doesn't account for returning a school\n",
    "#dataframe that is empty. Again, that HTML is still available for the school but because no other *W rows are saved,\n",
    "#we are okay with this school being omitted to maintain consistency.\n",
    "omit_error_indices = []\n",
    "for num, item in enumerate(list_of_dfs_with_metadata):\n",
    "    try:\n",
    "        item[0]['region'] = item[1]\n",
    "        item[0]['district'] = item[2]\n",
    "        item[0]['school'] = item[3]\n",
    "    except Exception as e:\n",
    "        print(num, e, item)\n",
    "        omit_error_indices.append(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Visually confirm that all omitted indices are because of schoolwide withdrawals/other asterisked subjects\n",
    "#If not, look deeper into why that school's scrape might have failed. Expected output: ['SUBJECTS', '*W']\n",
    "for omit in omit_error_indices:\n",
    "    print(pd.read_html(list_of_dfs[omit])[0][3].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the above has been confirmed to be only all-null schools then run this cell to save those to a json file\n",
    "list_of_excluded_all_null_schools = []\n",
    "for omit in omit_error_indices:\n",
    "    list_of_excluded_all_null_schools.append(l[omit])\n",
    "\n",
    "with open('./CompleteDatasets/failed_scrapes_2019.json', 'w') as f:\n",
    "    json.dump(list_of_excluded_all_null_schools, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dfs = [df for idx,df in enumerate(list_of_dfs) if idx not in omit_error_indices]\n",
    "\n",
    "#Map is nice\n",
    "all_psle = pd.concat([df for df in map(pd.DataFrame, filtered_dfs)])\n",
    "all_psle.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_psle.to_csv('./CompleteDatasets/necta_psle_2019.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ACSEE\n",
    "Produces three CSVs: student-level results (includes private and public/national centers), exam center performance (public/national centers), exam center subject level performance (public/national centers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list()\n",
    "\n",
    "with open('./scraper/export/csee.jl', 'r') as File:\n",
    "    for line in File:\n",
    "        l.append((json.loads(line)))\n",
    "    File.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick qa -- check that the number of items scraped matches the expected number\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page = requests.get(\"https://onlinesys.necta.go.tz/results/2019/csee/csee.htm\").text\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "all_hrefs = [h['href'].split('/')[-1] for h in soup.find_all('table')[2].find_all('a')] #picking just the school table\n",
    "#soup.find_all('table')[0] for some of the older acsee home pages that only have one table.\n",
    "\n",
    "print('Beautiful soup found this number of links:', len(all_hrefs))\n",
    "print('Scraper scraped this number of items:', len(l))\n",
    "#all_hrefs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_of_results = []\n",
    "\n",
    "for center in l:\n",
    "    list_of_results.append(center['result_table'])\n",
    "    \n",
    "all_acsee = pd.concat([df for df in map(pd.DataFrame, list_of_results)], sort=False) #sort=False better for column order\n",
    "#Scraper uses ! (exclamation mark) to denote empty field/NA during processing. Changing that back to np.nan.\n",
    "all_acsee = all_acsee.replace({'!': pd.np.nan}).sort_values(['exam_center', 'CNO'])\n",
    "all_acsee.rename(columns={'F': 'F & HN NUTRITION'}, inplace=True)\n",
    "del all_acsee['']\n",
    "\n",
    "#F column is: all_acsee_fullDF.rename(columns={'F': 'F & HN NUTRITION'}, inplace=True)\n",
    "#Empty string column, '', is *W *E *R students who don't have any subject data.\n",
    "\n",
    "all_acsee.to_csv('./CompleteDatasets/necta_csee_2019.csv', index=False)\n",
    "\n",
    "#keeping the info below for posterity, ease of access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanzania ina mifumo 2 ya utoaji elimu.\n",
    "1. Mfumo rasmi wa utoaji elimu ambapo wanafunzi wanasoma kutoka shule ya awali, msingi sekondari hadi chuo kikuu\n",
    "2. Mfumo usio rasmi wa utoaji elimu ambaopo mwanafunzi anajisomea mwenyewe kwenye vituo vya elimu na kisha wanafanya mtihani na inatambulika.\n",
    "\n",
    "Sasa unapokuja kwenye mitihani. Kituo cha mtihani yaani shule inaweza pia kuwa na kituo cha kufanya mtihani hapo sasa utaona tofauti ya namba.\n",
    "Wanafunzi wa shule wana namba zinazoanza na S.(means School candidate) na wale wasio rasmi wanaanza na P(means Private)\n",
    "Hivyo sio shule zote zina P.\n",
    "Ukiona kuna P hapo kuna wanafunzi ambao sio wanafunzi wa shule wanafanya mtihani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* S: Results suspended pending clarification of observed anomalies either in candidates' entry details, involvement in cases of irregularities or misconduct in the examination.Results suspended due to centers or schools' failing to meet registration requirements (i.e. centers with less than 35 candidates).\n",
    "\n",
    "* E: Results withheld, pending proof of candidates' payment of requisite Examination fees.\n",
    "\n",
    "* I: INCOMPLETE Results due to candidates' missing Continous Assessment (CA) scores in all subjects offered.\n",
    "\n",
    "I: Incomplete results due to candidates' missing Continous Assessment(CA) scores in one or more subjects offered but not all.\n",
    "\n",
    "* W: Results withheld/nullified or canceled due to proven candidate's involvement in cases of dishonesty or irregularities before, during or after the examinations.\n",
    "\n",
    "* T: Results suspended due to candidates' attempting one or more subjects not registered for (pirate candidate).\n",
    "\n",
    "ABS: Candidate missed to take the Exam.\n",
    "\n",
    "FLD: Candidate failed the Exam.\n",
    "\n",
    "X: Candidate did not appear to take the exam for the particular registered subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_of_rankings = []\n",
    "\n",
    "for center in l:\n",
    "    list_of_rankings.append(center['rankings_table'])\n",
    "    \n",
    "all_acsee_rankings = pd.concat([df for df in map(pd.DataFrame, list_of_rankings)], sort=False) #sort=False better for column order\n",
    "all_acsee_rankings = all_acsee_rankings.pivot(index='exam_center', columns='category', values='rank').reset_index()\n",
    "\n",
    "list_of_div_perform = []\n",
    "for center in l:\n",
    "    list_of_div_perform.append(center['div_performance_table'])\n",
    "all_acsee_div_perform = pd.concat([df for df in map(pd.DataFrame, list_of_div_perform)], sort=False) #sort=False better for column order\n",
    "all_acsee_div_perform\n",
    "\n",
    "#combine the two\n",
    "acsee_center_outcomes = pd.merge(all_acsee_rankings,\n",
    "                                 all_acsee_div_perform,\n",
    "                                 how='outer',\n",
    "                                 on='exam_center'\n",
    "                                )\n",
    "\n",
    "acsee_center_outcomes.to_csv('./CompleteDatasets/necta_csee_2019_center_performance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_of_subj_perform = []\n",
    "\n",
    "for center in l:\n",
    "    list_of_subj_perform.append(center['subject_performance_table'])\n",
    "    \n",
    "all_acsee_subj_perform = pd.concat([df for df in map(pd.DataFrame, list_of_subj_perform)], sort=False) #sort=False better for column order\n",
    "all_acsee_subj_perform\n",
    "\n",
    "all_acsee_subj_perform.to_csv('./CompleteDatasets/necta_csee_2019_subject_performance.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
