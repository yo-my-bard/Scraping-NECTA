{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acsee = pd.read_csv(\"CompleteDatasets/necta_acsee_2018.csv\")\n",
    "centersmeta = pickle.load(open('CompleteDatasets/centers_meta_2018.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Any noticeable performance differences between smaller schools and larger schools?\n",
    "\n",
    "divs = ['I', 'II', 'III', 'IV', '0']\n",
    "divs_pass = ['I', 'II']\n",
    "\n",
    "acsee['center'] = acsee['CNO'].apply(lambda x: x.split('/')[0])\n",
    "\n",
    "def get_region(center, centers_meta):\n",
    "    try:\n",
    "        return centers_meta[center]['rankings'].loc[0][1]\n",
    "    except AttributeError:\n",
    "        return np.nan\n",
    "\n",
    "def get_center_size(center, centers_meta):\n",
    "    try:\n",
    "        return centers_meta[center]['rankings'].loc[3][1]\n",
    "    except AttributeError:\n",
    "        return np.nan\n",
    "\n",
    "def get_tester_type(center):\n",
    "    if 'P' in center:\n",
    "        return 'Private'\n",
    "    else:\n",
    "        return 'School'\n",
    "\n",
    "def get_pass(div):\n",
    "    if div in divs_pass:\n",
    "        return 1\n",
    "    elif div in divs:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "acsee['passed'] = acsee['DIV'].apply(lambda x: get_pass(x))\n",
    "acsee['region'] = acsee['center'].apply(lambda x: get_region(x, centersmeta))\n",
    "acsee['centersize'] = acsee['center'].apply(lambda x: get_center_size(x, centersmeta))\n",
    "acsee['testertype'] = acsee['center'].apply(lambda x: get_tester_type(x))\n",
    "acsee['centersize'].value_counts() #This is the number of students/candidates within each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the % of students in each division\n",
    "print(\"Centers with 30 candidates or more\")\n",
    "print(acsee[acsee['DIV'].isin(divs)].groupby('centersize')['DIV'].value_counts()['CENTRE WITH 30 CANDIDATES OR MORE']/acsee[acsee['DIV'].isin(divs)]['centersize'].value_counts()['CENTRE WITH 30 CANDIDATES OR MORE'])\n",
    "print(\"\\nCenters with less than 30 candidates\")\n",
    "print(acsee[acsee['DIV'].isin(divs)].groupby('centersize')['DIV'].value_counts()['CENTRE WITH LESS THAN 30 CANDIDATES']/acsee[acsee['DIV'].isin(divs)]['centersize'].value_counts()['CENTRE WITH LESS THAN 30 CANDIDATES'])\n",
    "\n",
    "#The distribution is the same order for each group. DIV II is where most students land, followed by III, I, IV, 0.\n",
    "#+0.6% difference between divsion 0s. However, outside of a 2% difference between Division IIs, no noticeable diffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Well that's surprising, why isn't there a noticeable difference between the students from the two types of centers? Let's check to see\n",
    "#the spread of the number of students for each center.\n",
    "acsee[acsee['DIV'].isin(divs)].groupby('region').count()['CNO'] #students per region\n",
    "acsee[acsee['DIV'].isin(divs)].groupby(['center']).count()['CNO'] #students per center\n",
    "acsee[acsee['DIV'].isin(divs)].groupby(['center', 'centersize']).count()['CNO'] #students per center with centersize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of # of Students at the official size tiers\n",
    "fig, (ax1, ax2) = plt.subplots(ncols = 2)\n",
    "print(\"30 candidates or more - # of students distribution\\n\", acsee[acsee['DIV'].isin(divs)].groupby(['center', 'centersize']).count()['CNO'][:, 'CENTRE WITH 30 CANDIDATES OR MORE'].describe())\n",
    "acsee[acsee['DIV'].isin(divs)].groupby(['center', 'centersize']).count()['CNO'][:, 'CENTRE WITH 30 CANDIDATES OR MORE'].plot(kind='hist', ax = ax1,\n",
    "                                                                                                                            title = '30 or More')\n",
    "\n",
    "print(\"Less than 30 candidates - # of students distribution\\n\", acsee[acsee['DIV'].isin(divs)].groupby(['center', 'centersize']).count()['CNO'][:, 'CENTRE WITH LESS THAN 30 CANDIDATES'].describe())\n",
    "acsee[acsee['DIV'].isin(divs)].groupby(['center', 'centersize']).count()['CNO'][:, 'CENTRE WITH LESS THAN 30 CANDIDATES'].plot(kind='hist', ax = ax2,\n",
    "                                                                                                                              title = 'Less than 30')\n",
    "plt.close()\n",
    "fig.tight_layout()\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It seems it might be helpful to disaggregate the 30 or More group of schools\n",
    "center_students = pd.DataFrame(acsee[acsee['DIV'].isin(divs)].groupby(['center']).count()['CNO']).reset_index()\n",
    "center_students.rename(columns = {'CNO': 'numstudents'}, inplace=True)\n",
    "len(center_students[(center_students['numstudents'] > 200) & (center_students['numstudents'] < 300)])\n",
    "\n",
    "#Most are between 30 and 100 students\n",
    "#Possible new intervals 30-50, 50-75, 75-100, 100-200, 200-300, 300-900\n",
    "new_sizes = ['30-50', '50-75', '75-100', '100-200', '200-300', '300-900']\n",
    "new_sizes_dict = dict.fromkeys(new_sizes)\n",
    "for k,v in new_sizes_dict.items():\n",
    "    new_v = (int(k.split('-')[0]), int(k.split('-')[1]))\n",
    "    new_sizes_dict[k] = new_v\n",
    "\n",
    "for k,v in new_sizes_dict.items():\n",
    "    print(len(center_students[(center_students['numstudents'] >= v[0]) & (center_students['numstudents'] < v[1])]))\n",
    "#Not very scientifically done and groupings aren't as even as possible, but better distribution than 544 vs. 130.\n",
    "#Let's see how performance compares for this new disaggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#center_students\n",
    "acsee = acsee.merge(center_students, how = 'left', on='center')\n",
    "#acsee['new_centersize'] = if numstudents is >= first val and < second val of the value, then return the key\n",
    "new_sizes_dict['< 30'] = (0, 30)\n",
    "\n",
    "def get_new_centersize(num, sizesdict):\n",
    "    #rev sizesdict is tuple: 'interval'\n",
    "    for k, v in sizesdict.items():\n",
    "        if num >= v[0] and num < v[1]:\n",
    "            return k\n",
    "\n",
    "acsee['new_centersize'] = acsee['numstudents'].apply(lambda x: get_new_centersize(x, new_sizes_dict))\n",
    "acsee['new_centersize'].unique()\n",
    "\n",
    "#del acsee['numstudents_x'], acsee['numstudents_y'], acsee['new_centersize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(new_sizes_dict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#len(acsee[acsee.testertype == 'School'].groupby(['new_centersize', 'center'])['CNO'].count()['< 30']) should be 130\n",
    "\n",
    "#We've successfully assigned new size groupings. Let's run the analysis again with the new center sizes:\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 7, figsize = (10,30))\n",
    "\n",
    "for i in range(len(ax)):\n",
    "    print(list(new_sizes_dict.items())[i][0], acsee[(acsee['DIV'].isin(divs)) & (acsee['testertype'] == 'School')].groupby(['center', 'new_centersize']).count()['CNO'][:, list(new_sizes_dict.items())[i][0]].describe())\n",
    "    acsee[(acsee['DIV'].isin(divs)) & (acsee['testertype'] == 'School')].groupby(['center', 'new_centersize']).count()['CNO'][:, list(new_sizes_dict.items())[i][0]].plot(kind='hist', ax = ax[i], title = list(new_sizes_dict.items())[i][0])\n",
    "\n",
    "plt.close()\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"new_sizes_dist.png\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#The distributions look better and should allow us to better compare the performance at each size tier\n",
    "for i in range(7):\n",
    "    tier = list(new_sizes_dict.items())[i][0]\n",
    "    print(tier,\n",
    "          acsee[(acsee['DIV'].isin(divs)) & (acsee['testertype'] == 'School')].groupby(['new_centersize'])['DIV'].value_counts()[tier]/acsee[(acsee['DIV'].isin(divs)) & (acsee['testertype'] == 'School')]['new_centersize'].value_counts()[tier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#The new acceptable way to make categorical variables - unused for now, instead can use .reindex method\n",
    "from pandas.api.types import CategoricalDtype\n",
    "div_order = ['ABS', '*E', '*R', '*W', '0', 'IV', 'III', 'II', 'I'] #All values must be included in this list, otherwise will be turned to NaN when cat'd\n",
    "acsee['DIV'] = acsee['DIV'].astype(CategoricalDtype(div_order, ordered=True))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=7, figsize = (10,20))\n",
    "for i in range(7):\n",
    "    tier = ([list(new_sizes_dict.items())[-1]] + (list(new_sizes_dict.items())[0:-1]))[i][0]\n",
    "    print(tier,\n",
    "          (acsee[(acsee['DIV'].isin(divs)) & (acsee['testertype'] == 'School')].groupby(['new_centersize'])['DIV'].value_counts()[tier]/acsee[(acsee['DIV'].isin(divs)) & (acsee['testertype'] == 'School')]['new_centersize'].value_counts()[tier]).reindex(divs).plot(kind='bar', ax = ax[i], title = tier, color = 'navy', rot=0))\n",
    "    \n",
    "\n",
    "\n",
    "plt.close()\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"new_tiers_div_percentage_dist.png\")\n",
    "\n",
    "#Doing the same as above, but plotting instead, it's easier to see how the trend holds for every size tier except the largest.\n",
    "#The most promising size tier appears to be the 75-100 group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#A more rigorous hypothesis testing may fit here. I use a chi-square test to determine whether a student passing\n",
    "#is independent of their school's tier size. That is, given two or more school tier sizes are students equally likely\n",
    "#to pass. Chi-square compares the expected frequencies and observed frequencies to determine whether or not to\n",
    "#reject the null hypothesis: that there is no difference in passing rates between the school tiers.\n",
    "\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "#We need samples of each group\n",
    "\n",
    "subsamples = []\n",
    "for i in ['50-75', '300-900']:\n",
    "    subsample = acsee[(acsee['new_centersize'] == i) & (acsee['testertype'] == 'School') & (acsee['center'] != 'S0485')].sample(frac = 0.09)\n",
    "    subsamples.append(subsample)\n",
    "acsee_new_center_sample = pd.concat(subsamples)\n",
    "print(len(acsee_new_center_sample))\n",
    "\n",
    "subsamples = []\n",
    "for i in [e for e in acsee['centersize'].unique() if pd.notnull(e)]:\n",
    "    subsample = acsee[(acsee['centersize'] == i) & (acsee['testertype'] == 'School')].sample(frac = 0.09)\n",
    "    subsamples.append(subsample)\n",
    "acsee_gov_center_sample = pd.concat(subsamples)\n",
    "print(len(acsee_gov_center_sample))\n",
    "\n",
    "def generate_chitable(df, which_size = 'centersize'):\n",
    "    \"\"\"Return chi square calculation ready table\"\"\"\n",
    "    if which_size == 'centersize':\n",
    "        observed_passed = df.groupby('centersize')['passed'].sum() #observed passed\n",
    "        total_candidates = df.groupby('centersize')['passed'].count().rename(\"Total\") #total\n",
    "        observed_failed = (df.groupby('centersize')['passed'].count() - df.groupby('centersize')['passed'].sum()).rename(\"failed\") #observed not passed\n",
    "        chi_table = pd.concat([observed_passed, observed_failed, total_candidates], axis = 1)\n",
    "        chi_table_horizontal_total = chi_table.sum().rename(\"Total\")\n",
    "        chi_table = chi_table.append(chi_table_horizontal_total)\n",
    "        chi_table.index.rename(\"\", inplace=True)\n",
    "    else:\n",
    "        observed_passed = df.groupby('new_centersize')['passed'].sum() #observed passed\n",
    "        total_candidates = df.groupby('new_centersize')['passed'].count().rename(\"Total\") #total\n",
    "        observed_failed = (df.groupby('new_centersize')['passed'].count() - df.groupby('new_centersize')['passed'].sum()).rename(\"failed\") #observed not passed\n",
    "        chi_table = pd.concat([observed_passed, observed_failed, total_candidates], axis = 1)\n",
    "        chi_table_horizontal_total = chi_table.sum().rename(\"Total\")\n",
    "        chi_table = chi_table.append(chi_table_horizontal_total)\n",
    "        chi_table.index.rename(\"\", inplace=True)\n",
    "    \n",
    "    return chi_table\n",
    "\n",
    "\n",
    "def get_expected_values(chitable):\n",
    "    \"\"\"The return value is in the pattern of passed(row1), failed(row1), passed(row2), failed(row2)\"\"\"\n",
    "    e_values = []\n",
    "    for i in range(len(chitable)-1):\n",
    "        passed_e = (chitable.iloc[i, 2] * chitable.iloc[len(chitable)-1,0])/chitable['Total']['Total']\n",
    "        e_values.append(passed_e)\n",
    "        failed_e = (chitable.iloc[i, 2] * chitable.iloc[len(chitable)-1,1])/chitable['Total']['Total']\n",
    "        e_values.append(failed_e)\n",
    "    return np.array(e_values)\n",
    "\n",
    "def get_observed_values(chitable):\n",
    "    \"\"\"The return value is in the pattern of passed(row1), failed(row1), passed(row2), failed(row2)\"\"\"\n",
    "    o_values = []\n",
    "    for i in range(len(chitable)-1):\n",
    "        passed_o = chitable.iloc[i,0]\n",
    "        o_values.append(passed_o)\n",
    "        failed_o = chitable.iloc[i,1]\n",
    "        o_values.append(failed_o)\n",
    "    return np.array(o_values)\n",
    "\n",
    "\n",
    "#I find no significant differences between the official government groupings of the school, but the new groupings show\n",
    "#there is a significant difference p < 0.05. Not surprisingly, the driver of this difference appears to be the 300-900 group.\n",
    "#However, after removing the outlier schoool S0485, < 30 shows no significant difference in performance with 300-900 (now 600),\n",
    "#but the 75-100 group still has significantly different passing rates. As do the other mid-tier schools.\n",
    "print(chisquare(get_observed_values(generate_chitable(acsee_new_center_sample, \"new_centersize\")), get_expected_values(generate_chitable(acsee_new_center_sample, \"new_centersize\"))))\n",
    "\n",
    "print(chisquare(get_observed_values(generate_chitable(acsee_gov_center_sample)), get_expected_values(generate_chitable(acsee_gov_center_sample))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The p-value changes with every chi-square test. Let's look at the distribution of P-values if we ran multiple times.\n",
    "#I would run the test and often get p-values that are statistically significant, and others that are not.\n",
    "\n",
    "#For reference, new sizes: ['50-75', '< 30', '100-200', '75-100', '30-50', '200-300', '300-900', None]\n",
    "#Article: http://varianceexplained.org/statistics/interpreting-pvalue-histogram/\n",
    "p_vals = []\n",
    "rounds = 0\n",
    "\n",
    "while rounds < 100:\n",
    "    subsamples = []\n",
    "    for i in ['< 30', '300-900']:\n",
    "        subsample = acsee[(acsee['new_centersize'] == i) & (acsee['testertype'] == 'School') & (acsee['center'] != 'S0485')].sample(frac = 0.09)\n",
    "        subsamples.append(subsample)\n",
    "    acsee_new_center_sample = pd.concat(subsamples)\n",
    "\n",
    "    x, p = chisquare(get_observed_values(generate_chitable(acsee_new_center_sample, \"new_centersize\")), get_expected_values(generate_chitable(acsee_new_center_sample, \"new_centersize\")))\n",
    "    p_vals.append(p)\n",
    "    rounds += 1\n",
    "\n",
    "plt.hist(p_vals)\n",
    "plt.show()\n",
    "#50-75, < 30 conservative p-values\n",
    "#100-200, < 30 conservative\n",
    "#75-100, < 30 bimodal\n",
    "#200-300, < 30 conservative\n",
    "#300-900, < 30 weird/bimodal\n",
    "#50-75, 75-100 bimodal?\n",
    "#50-75, 100-200 conservative\n",
    "#50-75, 200-300 anti-conservative\n",
    "#50-75, 300-900 anti-conservative\n",
    "#75-100, 100-200 anti-conservative\n",
    "#75-100, 200-300 anti-conservative\n",
    "#75-100, 300-900 anti-conservative\n",
    "#100-200, 200-300 anti-conservative\n",
    "#100-200, 300-900 anti-conservative\n",
    "#200-300, 300-900 conservative\n",
    "\n",
    "#The anti-conservative ones (all have a very high % of alternative hypotheses):\n",
    "#50-75, 200-300 anti-conservative\n",
    "#50-75, 300-900 anti-conservative\n",
    "#75-100, 100-200 anti-conservative\n",
    "#75-100, 200-300 anti-conservative\n",
    "#75-100, 300-900 anti-conservative\n",
    "#100-200, 200-300 anti-conservative\n",
    "#100-200, 300-900 anti-conservative\n",
    "\n",
    "#From above, data shows that smaller tiers perform better on average. This appears to be statistically significant\n",
    "#for the comparisons that are exhibiting an anti-conservative distribution here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#For the regular centersize tiers\n",
    "\n",
    "p_vals = []\n",
    "rounds = 0\n",
    "while rounds < 500:\n",
    "    subsamples = []\n",
    "    for i in [e for e in acsee['centersize'].unique() if pd.notnull(e)]:\n",
    "        subsample = acsee[(acsee['centersize'] == i) & (acsee['testertype'] == 'School') & (acsee['center'] != 'S0485')].sample(frac = 0.09)\n",
    "        subsamples.append(subsample)\n",
    "    acsee_gov_center_sample = pd.concat(subsamples)\n",
    "\n",
    "    x, p = chisquare(get_observed_values(generate_chitable(acsee_gov_center_sample)), get_expected_values(generate_chitable(acsee_gov_center_sample)))\n",
    "    p_vals.append(p)\n",
    "    rounds += 1\n",
    "\n",
    "plt.hist(p_vals)\n",
    "plt.show()\n",
    "#The distribution looks like something (an assumption) is wrong with the test (according to the blog post).\n",
    "#And there likely is - the More than 30 or more group was had a left-skewed distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#If 75-100 seems to be doing well, does 75-100 tier schools correlate to any region?\n",
    "#Mtwara, the highest performing region, only had 5% of its students in the 75-100 size tier schools.\n",
    "#Kaskazini Pemba, the third lowest performing region, had the highest share of its students in schools in that tier.\n",
    "#Not too surprisingly, having a greater concentration of the best performing tier doesn't necessarily translate to performance.\n",
    "numstudentstier75 = acsee[(acsee['new_centersize'] == '75-100') & (acsee['DIV'].isin(divs))]['region'].value_counts()\n",
    "(numstudentstier75/acsee[(acsee['DIV'].isin(divs))]['region'].value_counts()).sort_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#When comparing to the concentration of _schools_ (not students) in that size, a similar story emerges.\n",
    "numschoolstier75 = acsee[(acsee['new_centersize'] == '75-100') & (acsee['DIV'].isin(divs))].groupby('region')['center'].unique().apply(lambda x: len(x))\n",
    "(numschoolstier75/acsee[(acsee['DIV'].isin(divs))].groupby('region')['center'].unique().apply(lambda x: len(x))).sort_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Total number of schools per each region - pretty large difference here in terms of the number of schools to manage.\n",
    "#However, Zanzibar schools and Pemba are an anomaly. Relatively fewer number of schools, but not high performing.\n",
    "#Likely because they are islands and don't receive as much resources in the way of education\n",
    "#but maybe they should, given that they're tourism hotspots. Similarly, I'd expect Katavi to perform better.\n",
    "acsee[(acsee['DIV'].isin(divs))].groupby('region')['center'].unique().apply(lambda x: len(x)).sort_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the top 3 regions, find their size tier distributions (number of students at each tier)\n",
    "top3numstudents = pd.DataFrame(acsee[(acsee['DIV'].isin(divs))].groupby(['region'])['new_centersize'].value_counts()[['GEITA', 'MTWARA', 'LINDI']] )\n",
    "top3numstudents.columns = ['numstudents']\n",
    "top3numstudents.reset_index(inplace=True)\n",
    "top3numstudents.set_index(['region', 'new_centersize'], inplace=True)\n",
    "\n",
    "#In order to divide just the three regions (or other select regions), the indices of the dividend/divisor need to match.\n",
    "#This is simple for a single index situation, but trickier for multi-index especially since the divisor is not a scalar -\n",
    "#the divisor is the total number of students in the region in question. We elect to have a multi-index so that we can have\n",
    "#clear size tier labels for the region without assuming. So we have to replicate the dividend dataframe, add the multi-indices as\n",
    "#columns of the new dataframe (totalstudents), reset so that we can map total values (which are scalars) based on the region,\n",
    "#set the multi-index for the new dataframe (totalstudents), then divide the two series.\n",
    "\n",
    "totalstudents = pd.DataFrame(index = top3numstudents.index, columns = ['totalstudents']).reset_index()\n",
    "studenttotals = dict(list(acsee[(acsee['DIV'].isin(divs))]['region'].value_counts()[list(top3numstudents.index.levels[0])].items()))\n",
    "totalstudents['totalstudents'] = totalstudents['region'].apply(lambda x: studenttotals[x] ) #if region is x, put y values\n",
    "totalstudents.set_index(['region', 'new_centersize'], inplace=True)\n",
    "top3numstudents['numstudents']/totalstudents['totalstudents']\n",
    "\n",
    "#Once again, if 75-100 seems to appear to be the _most_ optimal school size tier, a small proportion of the\n",
    "#students attend these schools in the highest performing regions. Suggesting that their success is not driven by tier \n",
    "#size alone. \n",
    "\n",
    "#A regression idea: passing % = size_tier_dummies + region_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If Kaskazini Pemba's 75-100 tier schools didn't carry it to the finish line, how did\n",
    "#the rest of the other regions' 75-100 tier schools do?\n",
    "numstudentstier75\n",
    "tier75passing = acsee[(acsee['DIV'].isin(divs_pass)) & (acsee['testertype'] == 'School') & (acsee['new_centersize'] == '75-100')].groupby('region').count()['CNO']\n",
    "\n",
    "(tier75passing/numstudentstier75).sort_values(0, ascending=False)\n",
    "\n",
    "#Top performing regions had high passing rates among students in the 75-100 tier schools.\n",
    "#If this is the spread for this tier, what about the other tiers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "region_size_pass = acsee[(acsee['DIV'].isin(divs_pass)) & (acsee['testertype'] == 'School') ].groupby(['region', 'new_centersize']).count()['CNO']\n",
    "region_size_total = acsee[(acsee['DIV'].isin(divs)) & (acsee['testertype'] == 'School')].groupby(['region', 'new_centersize']).count()['CNO']\n",
    "\n",
    "#(region_size_pass/region_size_total).to_frame().sort_values(['region', 'CNO']).to_csv(\"region_size_pass_rate.csv\")\n",
    "\n",
    "(region_size_pass/region_size_total).to_frame().sort_values(['region', 'CNO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#To easily compare different regions/center sizes, use pd.IndexSlice\n",
    "idx = pd.IndexSlice\n",
    "(region_size_pass/region_size_total).to_frame().sort_values(['region', 'CNO']).loc[idx[['DAR ES SALAAM', 'GEITA',\n",
    "                                                                                       'LINDI', 'MTWARA',\n",
    "                                                                                       'KASKAZINI PEMBA'], :], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is hard to see. A line plot with center sizes in order, and passing rates in y-axis to see trend would help\n",
    "from pandas.api.types import CategoricalDtype\n",
    "size_order = ['< 30', '30-50', '50-75', '75-100', '100-200', '200-300', '300-900'] #All values must be included in this list, otherwise will be turned to NaN when cat'd\n",
    "acsee['new_centersize'] = acsee['new_centersize'].astype(CategoricalDtype(size_order, ordered=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GROUP BY PLOT DOES WHAT I'VE BEEN MANUALLY DOING HERE WHAT\n",
    "#https://scentellegher.github.io/programming/2017/07/15/pandas-groupby-multiple-columns-plot.html\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "unstacked = (region_size_pass/region_size_total).to_frame().groupby(['new_centersize', 'region']).mean()['CNO'].unstack().reset_index()\n",
    "unstacked['new_centersize'] = unstacked['new_centersize'].astype(CategoricalDtype(size_order, ordered=True))\n",
    "unstacked.sort_values('new_centersize').plot('new_centersize', ax=ax, legend=False, title='Candidate passing rates as school tier size increases')\n",
    "plt.close()\n",
    "ax.set_ylabel('Passing Rate')\n",
    "ax.set_xlabel('School Tier Sizes: < 30 to 300-900 Candidates')\n",
    "fig.savefig('passing_rates_size_tier_increase.jpg')\n",
    "fig\n",
    "\n",
    "#This is providing another visual look at how passing rates change for candidates depending on which tier their school is in\n",
    "#The peak appears to be in the 75-100 tiers, and a downward slope from there\n",
    "#But I think the surprising information here is that there is a general upward trend from < 30 to 75-100, meaning\n",
    "#less may not always be more. And we can definitely disaggregate this further to look at regional zones as well\n",
    "#but overall, having too many students and too few appears to not be beneficial. (Each line is a region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#A follow up twitter question: https://twitter.com/BLACKSTEMUSA/status/1072129663114362880\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (20, 30))\n",
    "unstacked = (region_size_pass/region_size_total).to_frame().groupby(['new_centersize', 'region']).mean()['CNO'].unstack().reset_index()\n",
    "unstacked['new_centersize'] = unstacked['new_centersize'].astype(CategoricalDtype(size_order, ordered=True))\n",
    "axis = unstacked.sort_values('new_centersize').plot('new_centersize', subplots = True,\n",
    "                                             ax=ax, legend=False, sharey = True, color='navy',\n",
    "                                            layout = (8, 4), xticks = [0,1,2,3,4,5,6]) #xticks here uses the index, default use_index=True, because < causes error. This works because new_centersize is sorted\n",
    "\n",
    "plt.close()\n",
    "\n",
    "subplot_titles = list(unstacked.columns)[1:]\n",
    "title_num = 0\n",
    "for row in axis:\n",
    "    for plot in row:\n",
    "        if title_num >= len(subplot_titles):\n",
    "            continue\n",
    "        plot.set_xlabel('School Tier Sizes')\n",
    "        plot.set_title(subplot_titles[title_num])\n",
    "        title_num += 1\n",
    "fig.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "fig.suptitle(\"Candidate Passing Rates as School Tier Size Increases\", fontsize = 16)\n",
    "#fig.savefig(\"passing_rate_tier_size_2.jpg\", dpi = 600)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
